{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PLP9Q30PKtv"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5W9rkuBmBu9"
      },
      "source": [
        "# Bayesian Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIykBQbYXrXA"
      },
      "source": [
        "Bayesian models are at the heart of many ML applications, and they can be implemented in regression or classification. For example, the \"Naive Bayes\" algorithm has proven to be an excellent spam detection method. Bayesian inference is often used in applications of modeling stochastic, temporal, or time-series data, such as finance, healthcare, sales, marketing, and economics.  Bayesian networks are also at the heart of reinforcement learning (RL) algorithms, which drive complex automation, like autonomous vehicles. And Bayesian optimization is used to maximize the effectiveness of AI game opponents like [alphaGO](https://deepmind.com/research/case-studies/alphago-the-story-so-far).  Bayesian models make effective use of information, and it is possible to parameterize and update these models using prior and posterior probability functions.\n",
        "\n",
        "There are many libraries that implement probabilistic programming including [TensorFlow Probability](https://www.tensorflow.org/probability).  \n",
        "\n",
        "In this Colab we will implement a Bayesian model using a Naive Bayes classifier to predict the likelihood of spam in a sample of text data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR_Tz2pn1WMf"
      },
      "source": [
        "### Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jrdAklFCx-C"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8u2lYRWbE37"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3cNxL12_cMz"
      },
      "source": [
        "What is Naive Bayes?  There are two aspects: the first is naive, and the second is Bayes'. Let's first review the second part: Bayes' theorem from probability.\n",
        "\n",
        "$$ P(x)P(y|x) = P(y)P(x|y) $$\n",
        "\n",
        "Using this theorem, we can solve for the conditional probability of event $y$, given condition $x$.  Furthermore, Bayes' rule can be extended to incorporate $n$ vectors as follows:\n",
        "\n",
        "$$ P(y|x_1, ..., x_n) = \\frac{P(y)P(x_1, ..., x_n|y)}{P(x_1, ..., x_n)}$$\n",
        "\n",
        "These probability vectors can then be simplified by multiplying the individual conditional probability for each vector and taking the maximum likelihood. Naive Bayes returns the y value, or the category that maximizes the following argument.\n",
        "\n",
        "$$ \\hat{y} = argmax_y(P(y)\\prod_{i=1}^nP(x_i|y) $$\n",
        "\n",
        "Don't worry too much if this is a bit too much algebra. The actual implementations don't require us to remember everything!\n",
        "\n",
        "### But Wait, Why \"Naive\"?\n",
        "\n",
        "In this context, \"naive\" assumes that there is independence between pairs of conditional vectors. In other words, it assumes the features of your model are independent (or at least, have a low [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity)). This is typically not the case, and it is the cause for error. Naive Bayes is practically good for classification, but not for estimation. Furthermore, it is not robust to interaction, so some of your variables may have interactions. This comes up quite frequently in natural language processing (NLP), and so the usefulness of Naive Bayes is limited to simpler applications. Sometimes simple is better, like in spam filtering where Naive Bayes can perform reasonably well with limited training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vi3O347bIWz"
      },
      "source": [
        "## Spam Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LHNLjQ4sV6I"
      },
      "source": [
        "def LoadZip(url, file_name, cols=['type', 'message']):\n",
        "    # Download file.\n",
        "    urllib.request.urlretrieve(url, 'spam.zip')\n",
        "    # Open zip in memory.\n",
        "    with ZipFile('spam.zip') as myzip:\n",
        "        with myzip.open(file_name) as myfile:\n",
        "            df = pd.read_csv(myfile, sep='\\t', header=None)\n",
        "\n",
        "    df.columns=cols\n",
        "    display(df.head())\n",
        "    display(df.shape)\n",
        "    return df\n",
        "\n",
        "url = ('https://archive.ics.uci.edu/ml/machine-learning-databases/00228/'\n",
        "       'smsspamcollection.zip')\n",
        "df = LoadZip(url, 'SMSSpamCollection')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKrSKgU3zHoC"
      },
      "source": [
        "First let's analyze the number of spam vs. ham. For reference, \"ham\" is the opposite of \"spam\", so a non-spam message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLwafSIUzGrv"
      },
      "source": [
        "sns.countplot(df['type'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP7Dp8t00I4Q"
      },
      "source": [
        "Here we notice a class imbalance with under 1000 spam messages out of over 5000 total messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKB4EJ761-ho"
      },
      "source": [
        "Now we create a list of keywords that might indicate spam and generate features columns for each keyword.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NSy7WYCt4g0"
      },
      "source": [
        "features = pd.DataFrame()\n",
        "keywords = ['selected', 'win','deal', 'free', 'trip', 'urgent', 'require',\n",
        "            'need', 'cash', 'asap']\n",
        "\n",
        "# Use regex search built into pandas.\n",
        "for k in keywords:\n",
        "    features[k]=df['message'].str.contains(k, case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u29iAoBR38nG"
      },
      "source": [
        "Let's look at the correlation of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qaAHAk53_XC"
      },
      "source": [
        "features['allcaps'] = df['message'].str.isupper()\n",
        "sns.heatmap(features.corr())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHZwDW7uE-0L"
      },
      "source": [
        "The heatmap shows only weak correlations between variables like 'cash', 'win', 'free', and 'urgent'.  Therefore, we can assume there is independence between each keyword. In actuality, we are violating this assumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkaWZj0Y5WDs"
      },
      "source": [
        "## Train a Model to Predict Spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvRDb-m6360O"
      },
      "source": [
        "np.random.seed(seed=0)\n",
        "X = features\n",
        "y = df['type']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "sns.countplot(y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxpi8kjd5fpK"
      },
      "source": [
        "Using `features`, we will now make predictions on whether an individual message is spam or ham."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US0BySNq5g5c"
      },
      "source": [
        "def classifyNB(X_train,y_train, X_test, y_test, cols=['spam', 'ham']):\n",
        "    nb = BernoulliNB()\n",
        "\n",
        "    nb.fit(X_train,y_train)\n",
        "\n",
        "    y_pred = nb.predict(X_test)\n",
        "    class_names = cols\n",
        "    print('Classification Report')\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=class_names)\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "\n",
        "    sns.heatmap(df_cm, cmap='Blues', annot=True, fmt=\"d\",\n",
        "                xticklabels=True, yticklabels=True, cbar=False, square=True)\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.suptitle(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "    \n",
        "classifyNB(X_train,y_train,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCL48RLyoabw"
      },
      "source": [
        "The confusion matrix reads as follows:\n",
        "\n",
        "* 1182 ham messages correctly predicted\n",
        "* 114 ham messages were predicted to be spam (Type II error)\n",
        "* 71 spam messages were correctly predicted\n",
        "* 26 spam messages were erroneously predicted to be ham (Type I error)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-opQR47Tdhu"
      },
      "source": [
        "### Precision and Recall\n",
        "\n",
        "Remember that precision and recall are derived from the ground truth. Review the diagram below for clarification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaW0wGp6Si7L"
      },
      "source": [
        "%%html\n",
        "\n",
        "<a title=\"Walber [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], via Wikimedia Commons\" \n",
        "   href=\"https://commons.wikimedia.org/wiki/File:Precisionrecall.svg\">\n",
        "    <img width=\"256\" alt=\"Precisionrecall\" \n",
        "         src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/256px-Precisionrecall.svg.png\">\n",
        "</a>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlKMwRYaBNgG"
      },
      "source": [
        "For email, what's more important: spam detection or ham protection?\n",
        "\n",
        "In the case of your inbox, I don't think anyone wants to have legitimate email end up in the spam folder. On the other hand, your organization may be the target of phishing, and it may be important to filter out all spam aggressively. The answer to the question depends on the situation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WFLU7hWbO8_"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* [Naive Bayes docs](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
        "* [Spam dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)\n",
        "* [Sentiment reviews](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)\n",
        "* [Paper on classifiers](http://mdenil.com/static/papers/2015-deep-multi-instance-learning.pdf)\n",
        "* [Bayesian fnference](https://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swt2fxm-fG_B"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWq38ASlb2aY"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECfJaKHhBqAk"
      },
      "source": [
        "Let's load some user reviews data and do a sentiment analysis. Download the text data from [this UCI ML archive](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences).\n",
        "\n",
        "Create a classifier using Naive Bayes for one of the three datasets in the cell below. See how it performs on the other two sets of reviews. Comment on your approach to building features and why that may or may not work well for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz_hmP64BMWD"
      },
      "source": [
        "url = ('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
        "'00331/sentiment%20labelled%20sentences.zip')\n",
        "\n",
        "cols = ['message', 'sentiment']\n",
        "folder = 'sentiment labelled sentences'\n",
        "print('\\nYelp')\n",
        "df_yelp = LoadZip(url, folder+'/yelp_labelled.txt', cols)\n",
        "print('\\nAmazon')\n",
        "df_amazon = LoadZip(url, folder+'/amazon_cells_labelled.txt', cols)\n",
        "print('\\nImdb')\n",
        "df_imdb = LoadZip(url, folder+'/imdb_labelled.txt', cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYZEXNK1VDIJ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI_WxOyjcfNu"
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEivhvskVyF6"
      },
      "source": [
        "---"
      ]
    }
  ]
}