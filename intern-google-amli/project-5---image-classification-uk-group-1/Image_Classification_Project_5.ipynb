{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image Classification Project 5",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "yFwKrxE38t9S"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFwKrxE38t9S"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpcrMDk48nqI"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZOeKjw8waH"
      },
      "source": [
        "# Image Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4gLspcipN_n"
      },
      "source": [
        "###Group Members: Patricia, Javi, Jalen\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNmOFXz6p1Wp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK5j0BXxrbfX"
      },
      "source": [
        "In this project we will build an image classification model and use the model to identify if the lungs pictured indicate that the patient has pneumonia. The outcome of the model will be true or false for each image.\n",
        "\n",
        "The [data is hosted on Kaggle](https://www.kaggle.com/rob717/pneumonia-dataset) and consists of 5,863 x-ray images. Each image is classified as 'pneumonia' or 'normal'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ht1GVr68swO"
      },
      "source": [
        "## Ethical Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW94_8-98vpR"
      },
      "source": [
        "We will frame the problem as:\n",
        "\n",
        "> *A hospital is having issues correctly diagnosing patients with pneumonia. Their current solution is to have two trained technicians examine every patient scan. Unfortunately, there are many times when two technicians are not available, and the scans have to wait for multiple days to be interpreted.*\n",
        ">\n",
        "> *They hope to fix this issue by creating a model that can identify if a patient has pneumonia. They will have one technician and the model both examine the scans and make a prediction. If the two agree, then the diagnosis is accepted. If the two disagree, then a second technician is brought in to provide their analysis and break the tie.*\n",
        "\n",
        "Discuss some of the ethical considerations of building and using this model. \n",
        "\n",
        "* Consider potential bias in the data that we have been provided. \n",
        "* Should this model err toward precision or accuracy?\n",
        "* What are the implications of massively over-classifying patients as having pneumonia?\n",
        "* What are the implications of massively under-classifying patients as having pneumonia?\n",
        "* Are there any concerns with having only one technician make the initial call?\n",
        "\n",
        "The questions above are prompts. Feel free to bring in other considerations you might have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgUwTn_K-iK6"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0zCRDT-j58"
      },
      "source": [
        "* Each x-ray scan is a different patient so there could be underlying conditions across each patient. \"Normal\" x-rays may have other conditions that could affect the model.\n",
        "\n",
        "* Since we want to detect pnemonia as early as possible the model should lean more towards accuracy. The model should try to detect the slightest hint of pnemonia. However, this may lead to more work for the doctors. If we lean more towards precision, we could miss potential diagnoses, but the doctors would have to make less decisions to go through.\n",
        "\n",
        "* Some implication of massively over classifying patients as having pneumonia is the fact that they could prescribe unnecessary medication which could lead to potential health complications down the line. An implication of massively under classifying patients as having pneumonia is the potential of having individuals go home with an undiagnosed condition which could lead to death.\n",
        "* There could possibly be some sampling bias depending on the age range that the dataset is skewed towards if it is. Body parts change as we grow older and i am sure that the way pneumonia looks on a 5 year old, is different from how it looks on a 80 year old.\n",
        "\n",
        "* If someone is diagnosed with having pneumonia and they actually do not, they could miss work, pay for medicine they do not need, and hospital costs that are unneccessary.\n",
        "\n",
        "* If someone with pneumonia is not diagnosed they could possibly infect many others, be very sick themselves and not get the proper care and even in extreme cases, die.\n",
        "\n",
        "* Having two technicians agree on a diagnosis is the smartest way to do it because that eliminates the chances of a mistake. It is concerning that if only one makes the call, there is possibility they could be wrong which is why technology could be useful in the near future\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9AxwuxE-nQt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZFanABOAoHl"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxnS0ZlQAqNj"
      },
      "source": [
        "In this section of the lab, you will build, train, test, and validate a model or models. The data is the [\"Detecting Pneumonia\" dataset](https://www.kaggle.com/rob717/pneumonia-dataset). You will build a binary classifier that determines if an x-ray image has pneumonia or not.\n",
        "\n",
        "You'll need to:\n",
        "\n",
        "* Download the dataset\n",
        "* Perform EDA on the dataset\n",
        "* Build a model that can classify the data\n",
        "* Train the model using the training portion of the dataset. (It is already split out.)\n",
        "* Test at least three different models or model configurations using the testing portion of the dataset. This step can include changing model types, adding and removing layers or nodes from a neural network, or any other parameter tuning that you find potentially useful. Score the model (using accuracy, precision, recall, F1, or some other relevant score(s)) for each configuration.\n",
        "* After finding the \"best\" model and parameters, use the validation portion of the dataset to perform one final sanity check by scoring the model once more with the hold-out data.\n",
        "* If you train a neural network (or other model that you can get epoch-per-epoch performance), graph that performance over each epoch.\n",
        "\n",
        "Explain your work!\n",
        "\n",
        "> *Note: You'll likely want to [enable GPU in this lab](https://colab.research.google.com/notebooks/gpu.ipynb) if it is not already enabled.*\n",
        "\n",
        "If you get to a working solution you're happy with and want another challenge, you'll find pre-trained models on the [landing page of the dataset](https://www.kaggle.com/paultimothymooney/detecting-pneumonia-in-x-ray-images). Try to load one of those and see how it compares to your best model.\n",
        "\n",
        "Use as many text and code cells as you need to for your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XM35vYWSbim"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDu6faGJssHE"
      },
      "source": [
        "#### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXj05KRRsCJM"
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && cp kaggle.json ~/.kaggle/ && echo 'Done'\n",
        "! kaggle datasets download paultimothymooney/chest-xray-pneumonia\n",
        "! unzip chest-xray-pneumonia.zip\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRgSvh4psxRv"
      },
      "source": [
        "#### EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2PIG0l0zwJb"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "%matplotlib inline\n",
        "\n",
        "train_dir = 'chest_xray/train' # image folder\n",
        "test_dir = 'chest_xray/test' # image folder\n",
        "val_dir = 'chest_xray/val' # image folder\n",
        "\n",
        "# get the list of jpegs from sub image class folders\n",
        "train_normal_imgs = [fn for fn in os.listdir(f'{train_dir}/NORMAL') if fn.endswith('.jpeg')]\n",
        "train_pneumo_imgs = [fn for fn in os.listdir(f'{train_dir}/PNEUMONIA') if fn.endswith('.jpeg')]\n",
        "\n",
        "# get the list of jpegs from sub image class folders\n",
        "test_normal_imgs = [fn for fn in os.listdir(f'{test_dir}/NORMAL') if fn.endswith('.jpeg')]\n",
        "test_pneumo_imgs = [fn for fn in os.listdir(f'{test_dir}/PNEUMONIA') if fn.endswith('.jpeg')]\n",
        "\n",
        "# get the list of jpegs from sub image class folders\n",
        "val_normal_imgs = [fn for fn in os.listdir(f'{val_dir}/NORMAL') if fn.endswith('.jpeg')]\n",
        "val_pneumo_imgs = [fn for fn in os.listdir(f'{val_dir}/PNEUMONIA') if fn.endswith('.jpeg')]\n",
        "\n",
        "print(len(train_normal_imgs), len(train_pneumo_imgs), len(test_normal_imgs), len(test_pneumo_imgs), len(val_normal_imgs), len(val_pneumo_imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJwh4DU_5eGb"
      },
      "source": [
        "train_dir = './chest_xray/train'\n",
        "train_categories = set(os.listdir(train_dir))\n",
        "test_dir = 'chest_xray/test'\n",
        "test_categories = set(os.listdir(test_dir))\n",
        "\n",
        "if train_categories.symmetric_difference(test_categories):\n",
        "  print(\"Warning!: \", train_categories.symmetric_difference(test_categories))\n",
        "\n",
        "print(sorted(train_categories))\n",
        "print(len(train_categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io3fIE-91Yt2"
      },
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_dir = os.path.join(train_dir, 'NORMAL')\n",
        "img = cv.imread(os.path.join(sample_dir, os.listdir(sample_dir)[0]))\n",
        "_ = plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjmCDDpf7YGI"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXr_vnFi7jLy"
      },
      "source": [
        "img.min(), img.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0-JhkdKH3GU"
      },
      "source": [
        "Now we need to find a way to get the images into the model. TensorFlow Keras has a class called [`DirectoryIterator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator) that can help with that.\n",
        "\n",
        "The iterator pulls images from a directory and passes them to our model in batches. There are many settings we can change. In our example here, we set the `target_size` to the size of our input images. Notice that we don't provide a third dimension even though these are RGB files. This is because the default `color_mode` is `'rgb'`, which implies three values.\n",
        "\n",
        "We also set `image_data_generator` to `None`. If we wanted to, we could have passed an [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) to augment the image and increase the size of our dataset. We'll save this for an exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPRFN8_H5o-"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dir = 'chest_xray/train'\n",
        "\n",
        "train_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(100, 100),\n",
        "    directory=train_dir,\n",
        "    batch_size=128,\n",
        "    image_data_generator=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEYbHTgEZVov"
      },
      "source": [
        "print(train_image_iterator.filepaths[np.where(train_image_iterator.labels == 0)[0][0]])\n",
        "print(train_image_iterator.filepaths[np.where(train_image_iterator.labels == 1)[0][0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBq0mvM2BFFa"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyiyMgh5MSRP"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                           input_shape=(100, 100, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUnosERsR5iC"
      },
      "source": [
        "Now let's start training. Let one or two epochs run but then **!!!! STOP THE CELL FROM RUNNING !!!!**\n",
        "\n",
        "How long was each epoch taking? Ours was taking about `4` minutes. Let's do the math. If each epoch took `4` minutes and we ran `100` epochs, then we'd be training for `400` minutes. That's just under `7` hours of training!\n",
        "\n",
        "Luckily there is a better way. In the menu click on 'Runtime' and then 'Change runtime type'. In the modal that appears, there is an option called 'Hardware accelerator' that is set to 'None'. Change this to 'GPU' and save your settings.\n",
        "\n",
        "Your runtime will change, so you'll need to go back to the start of this section and run all of the cells from the start. Don't forget to upload your `kaggle.json` again.\n",
        "\n",
        "When you get back to this cell a second time and start it running, you should notice a big improvement in training time. We were getting `9` seconds per epoch, which is about `900` seconds total. This totals `15` minutes, which is much better. Let the cell run to completion (hopefully about `15` minutes). You should see it progressing as it is running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMidmU_EMUTu"
      },
      "source": [
        "history = model.fit(\n",
        "    train_image_iterator,\n",
        "    epochs=5,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNzOc52MUo4L"
      },
      "source": [
        "##### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL0IZZjYSl6D"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-HlbpSdUskN"
      },
      "source": [
        "And our loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ova5HkZhSnYp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))), history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOpyloTfUvEV"
      },
      "source": [
        "Over `99%` training accuracy. Let's see how well this generalizes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzlENPPuGTtf"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "test_dir = 'chest_xray/test'\n",
        "\n",
        "test_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(100, 100),\n",
        "    directory=test_dir,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    image_data_generator=None)\n",
        "\n",
        "model.evaluate(test_image_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hVo041SIXfT"
      },
      "source": [
        "We can also make predictions. The code below selects the next batch, gets predictions for it, and then returns the first prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku4AlEdTIC0W"
      },
      "source": [
        "predicted_class = np.argmax(model(next(test_image_iterator)[0])[0])\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUp-vD-TIn6s"
      },
      "source": [
        "This maps to the directory in that position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJYaW1x3U9vf"
      },
      "source": [
        "os.listdir(train_dir)[predicted_class]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69bV5TmEA0gU"
      },
      "source": [
        "##### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnebTAPf_du1"
      },
      "source": [
        "# f1 score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "actual_classes = test_image_iterator.classes\n",
        "\n",
        "predictions = model.predict(test_image_iterator)\n",
        "\n",
        "predicted_classes = [np.argmax(p) for p in predictions]\n",
        "\n",
        "f1_score(actual_classes, predicted_classes, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AofY1xVB1Dm"
      },
      "source": [
        "#### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o0nherNIzzc"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dir = 'chest_xray/train'\n",
        "\n",
        "train_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(50, 50), # changed target size\n",
        "    directory=train_dir,\n",
        "    batch_size=256, # changed batch size\n",
        "    image_data_generator=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoOBJm2_B10Z"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                           input_shape=(50, 50, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqG9ySYZB10Z"
      },
      "source": [
        "Now let's start training. Let one or two epochs run but then **!!!! STOP THE CELL FROM RUNNING !!!!**\n",
        "\n",
        "How long was each epoch taking? Ours was taking about `4` minutes. Let's do the math. If each epoch took `4` minutes and we ran `100` epochs, then we'd be training for `400` minutes. That's just under `7` hours of training!\n",
        "\n",
        "Luckily there is a better way. In the menu click on 'Runtime' and then 'Change runtime type'. In the modal that appears, there is an option called 'Hardware accelerator' that is set to 'None'. Change this to 'GPU' and save your settings.\n",
        "\n",
        "Your runtime will change, so you'll need to go back to the start of this section and run all of the cells from the start. Don't forget to upload your `kaggle.json` again.\n",
        "\n",
        "When you get back to this cell a second time and start it running, you should notice a big improvement in training time. We were getting `9` seconds per epoch, which is about `900` seconds total. This totals `15` minutes, which is much better. Let the cell run to completion (hopefully about `15` minutes). You should see it progressing as it is running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gnWYDrdB10Z"
      },
      "source": [
        "history = model.fit(\n",
        "    train_image_iterator,\n",
        "    epochs=5,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKw7ehYGB10a"
      },
      "source": [
        "##### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB2VAZ6SB10a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aGQEJecB10a"
      },
      "source": [
        "And our loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtQxjOcVB10a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))), history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoFfngKOB10a"
      },
      "source": [
        "Over `99%` training accuracy. Let's see how well this generalizes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcen-x8B10a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "test_dir = 'chest_xray/test'\n",
        "\n",
        "test_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(50, 50),\n",
        "    directory=test_dir,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    image_data_generator=None)\n",
        "\n",
        "model.evaluate(test_image_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCkETai4B10a"
      },
      "source": [
        "We can also make predictions. The code below selects the next batch, gets predictions for it, and then returns the first prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDTjcGgwB10a"
      },
      "source": [
        "predicted_class = np.argmax(model(next(test_image_iterator)[0])[0])\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgy8P1XwB10a"
      },
      "source": [
        "This maps to the directory in that position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-4BwLNtB10b"
      },
      "source": [
        "os.listdir(train_dir)[predicted_class]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ9kKH56B10b"
      },
      "source": [
        "##### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvCVH0T0B10b"
      },
      "source": [
        "# f1 score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "actual_classes = test_image_iterator.classes\n",
        "\n",
        "predictions = model.predict(test_image_iterator)\n",
        "\n",
        "predicted_classes = [np.argmax(p) for p in predictions]\n",
        "\n",
        "f1_score(actual_classes, predicted_classes, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsLyT8PZB10Z"
      },
      "source": [
        "#### Model 3 (Best Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6s7uCPUCyzm"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dir = 'chest_xray/train'\n",
        "\n",
        "train_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(50, 50), # changed target size\n",
        "    directory=train_dir,\n",
        "    batch_size=256, # changed batch size\n",
        "    image_data_generator=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KZCFy2FB1Dn"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                           input_shape=(50, 50, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlxDN3s-B1Dn"
      },
      "source": [
        "Now let's start training. Let one or two epochs run but then **!!!! STOP THE CELL FROM RUNNING !!!!**\n",
        "\n",
        "How long was each epoch taking? Ours was taking about `4` minutes. Let's do the math. If each epoch took `4` minutes and we ran `100` epochs, then we'd be training for `400` minutes. That's just under `7` hours of training!\n",
        "\n",
        "Luckily there is a better way. In the menu click on 'Runtime' and then 'Change runtime type'. In the modal that appears, there is an option called 'Hardware accelerator' that is set to 'None'. Change this to 'GPU' and save your settings.\n",
        "\n",
        "Your runtime will change, so you'll need to go back to the start of this section and run all of the cells from the start. Don't forget to upload your `kaggle.json` again.\n",
        "\n",
        "When you get back to this cell a second time and start it running, you should notice a big improvement in training time. We were getting `9` seconds per epoch, which is about `900` seconds total. This totals `15` minutes, which is much better. Let the cell run to completion (hopefully about `15` minutes). You should see it progressing as it is running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5sr-50VB1Dn"
      },
      "source": [
        "history = model.fit(\n",
        "    train_image_iterator,\n",
        "    epochs=5,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AKumaxBB1Dn"
      },
      "source": [
        "##### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL_ive4yB1Do"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgTUWMTIB1Do"
      },
      "source": [
        "And our loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjKcwvlcB1Do"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))), history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u3G-tbnB1Do"
      },
      "source": [
        "Over `99%` training accuracy. Let's see how well this generalizes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roamDhDnB1Do"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "test_dir = 'chest_xray/test'\n",
        "\n",
        "test_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(50, 50),\n",
        "    directory=test_dir,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    image_data_generator=None)\n",
        "\n",
        "model.evaluate(test_image_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpYgM2yZB1Do"
      },
      "source": [
        "We can also make predictions. The code below selects the next batch, gets predictions for it, and then returns the first prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFG4ewLNB1Dp"
      },
      "source": [
        "predicted_class = np.argmax(model(next(test_image_iterator)[0])[0])\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZUitSuHB1Dp"
      },
      "source": [
        "This maps to the directory in that position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGpoz95B1Dp"
      },
      "source": [
        "os.listdir(train_dir)[predicted_class]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYqXq1JEB1Dp"
      },
      "source": [
        "##### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO9Bi-vnB1Dp"
      },
      "source": [
        "# f1 score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "actual_classes = test_image_iterator.classes\n",
        "\n",
        "predictions = model.predict(test_image_iterator)\n",
        "\n",
        "predicted_classes = [np.argmax(p) for p in predictions]\n",
        "\n",
        "f1_score(actual_classes, predicted_classes, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpWe32qLCIX3"
      },
      "source": [
        "#### Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp7q65lXCLbS"
      },
      "source": [
        "val_dir = 'chest_xray/val'\n",
        "val_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    target_size=(50, 50),\n",
        "    directory=val_dir,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    image_data_generator=None)\n",
        "model.fit(val_image_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RQmROuVIZiF"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# f1 score\n",
        "actual_classes = val_image_iterator.classes\n",
        "\n",
        "predictions = model.predict(val_image_iterator)\n",
        "\n",
        "predicted_classes = [np.argmax(p) for p in predictions]\n",
        "\n",
        "f1_score(actual_classes, predicted_classes, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5AaFcUV8NCB"
      },
      "source": [
        "---"
      ]
    }
  ]
}